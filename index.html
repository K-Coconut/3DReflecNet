<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>3DReflectNet</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">3DReflecNet: A Million-Scale Hybrid Dataset for 3D Reconstruction of Reflective, Transparent, and Textureless Objects</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                    Anynomous Author
                  </span>
                </div>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(Coming Soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1AHyTFkta_bLA2iayU7R8MhaD_KRJAh_Q?usp=sharing" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="Teaser Image" style="width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        3D ReflectNet: A large-scale multi-view, object-centric dataset featuring reflective, transparent, and textureless objects. Providing high-quality annotations for 3D reconstruction.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurate 3D reconstruction of objects with reflective, transparent, or textureless surfaces remains a significant challenge. Such materials often violate key assumptions in multi-view reconstruction pipelines, such as photometric consistency and the reliance on distinct geometric texture cues. Existing datasets primarily focus on diffuse, textured objects, thereby offering limited insight into performance under real-world material complexities. In this paper, we introduce \textbf{\method}, a million-scale hybrid dataset specifically designed to benchmark and advance 3D reconstruction methods for these challenging materials. \method combines over 100,000 synthetic instances generated via physically-based rendering with more than 1,000 real-world scanned objects captured using consumer RGB-D devices. It encompasses diverse materials, complex lighting conditions, and a wide range of geometric forms‚Äîincluding shapes generated from both real and LLM-synthesized 2D images using diffusion-based methods. To support robust evaluation, we design benchmarks for five core tasks: structure-from-motion, novel view synthesis, reflection removal, image matching, and object relighting. Through extensive experiments, we show that state-of-the-art methods struggle to maintain accuracy across these settings, highlighting the need for more resilient 3D vision models. We release the dataset, baselines, and evaluation suite to facilitate progress in this direction.          </p>
          </p>
          </div>        
      </div>
    </div>
  </div>

</section>
<!-- End paper abstract -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3 has-text-centered">Comparison with Related Dataset</h2>
          <div style="margin: 2em auto; text-align: center;">
            <div>
              <img src="static/images/comparison.png" 
                  alt="Comparison and statistics overview"
                  style="width: 100%; max-width: 800px; height: auto; margin: auto;">
              <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
                Figure 3: Comparison between other related datasets. The symbol ‚Äú#‚Äù denotes the total count, ‚ÄúPBR‚Äù refers to physically-based rendering, and ‚Äúw/ Real‚Äù indicates the inclusion of real-world data.
              </p>
            </div>

            <div style="margin-top: 3em;">
              <img src="static/images/statistics.png" 
                  alt="Summary statistics of the 3DReflecNet dataset"
                  style="width: 100%; max-width: 800px; height: auto; margin: auto;">
              <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
                Figure 4: Summary statistics of the 3DReflecNet dataset.
              </p>
            </div>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3 has-text-centered">Dataset Overview</h2>
        
        <div class="content has-text-centered" style="margin-bottom: 2em;">
          <p style="font-size: 1.1em;">For material details, please refer to our <a href="assets/material.pdf" style="color: #3273dc;">material specifications</a> üìÑ</p>
          <p style="font-size: 1.1em;">You can download the <code style="background-color: #f1f1f1; padding: 0.2em 0.4em; margin: 0; font-size: 95%; border-radius: 6px; color: #e83e8c;">.blend</code> file containing all materials <a href="https://gofile.me/7IL4k/ORMCynUxL" style="color: #3273dc;">here</a> üì¶</p>
      </div>

        <div style="margin: 2em auto; text-align: center;">
            <div>
              <img src="static/images/Overview.png" 
                   alt="Comparison and statistics overview" 
                   style="width: 100%; max-width: 800px; height: auto; margin: auto;">
              <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
                Synthesis Dataset: Qualitative examples of the object with various materials with Lighting dataset.
              </p>
            </div>
        </div>

        <div style="margin: 2em auto; text-align: center;">
            <div>
              <img src="static/images/gold-colmap.png" 
                   alt="Summary statistics of the 3DReflecNet dataset." 
                   style="width: 100%; max-width: 800px; height: auto; margin: auto;">
              <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
                Real Dataset: Qualitative examples for Capturing Reflective Objects using Rotating platforms.
              </p>
            </div>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <h2 class="title is-3 has-text-centered">Benchmark Result</h2>
  
          <div style="margin: 2em auto; text-align: center;">
            <div>
            <img src="static/images/Image Matching.png" 
                 alt="Benchmark Image Matching Performance" 
                 style="width: 100%; max-width: 800px; height: auto; margin: auto;">
            <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
              Benchmark Image Matching Performance on the 3DReflecNet dataset. The italics letter represent the result for MegaDepth dataset
            </p>
            </div>
          </div>
  
          <div style="margin: 2em auto; text-align: center;">
            <div>
            <img src="static/images/Camera_Pose_Estimation.png" 
                 alt="Camera Pose Estimation" 
                 style="width: 100%; max-width: 800px; height: auto; margin: auto;">
            <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
              Camera Pose Estimation
            </p>
            </div>
          </div>
  
          <div style="margin: 2em auto; text-align: center;">
            <div>
            <img src="static/images/NVS.png" 
                 alt="Novel View Synthesis" 
                 style="width: 100%; max-width: 800px; height: auto; margin: auto;">
            <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
              Qualitative results of 2DGS surface reconstruction fidelity across various materials. (b)Qualitative results of 3DGS novel view synthesis visual quality.
            </p>
            </div>
          </div>
  
          <div style="margin: 2em auto; text-align: center;">
            <div>
            <img src="static/images/surface-recon.png" 
                 alt="Surface Reconstruction Performance" 
                 style="width: 100%; max-width: 800px; height: auto; margin: auto;">
            <p style="font-size: 1.2em; color: #666; margin-top: 0.5em;">
              Benchmark Surface Reconstruction Performance on the 3DReflecNet dataset. The metric is Chamfer Distance.
            </p>
            </div>
          </div>
  
        </div>
      </div>
    </div>
</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
  </html>